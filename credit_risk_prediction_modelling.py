# -*- coding: utf-8 -*-
"""Credit Risk Prediction Modelling.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-gwr9RESyjG7Ia5D2ZyqESucxxK80ppA

# `IMPORT LIBRARIES`

---
"""

import numpy as np
import math
import pandas as pd
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', 99)
from google.colab import autoviz
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()

"""# `IMPORT DATA`

---
"""

from google.colab import drive
drive.mount('/content/drive')

data = pd.read_csv('/content/drive/MyDrive/data/loan_data_2007_2014.csv', index_col=0)

"""#` EXPLORING DATA `

---
"""

data.shape

data.info()

catCols = ['home_ownership'
                ,'pymnt_plan'
                ,'verification_status'
                ,'next_pymnt_d'
                ,'addr_state'
                ,'earliest_cr_line'
                ,'title'
                ,'application_type'
                ,'last_pymnt_d'
                ,'emp_length_int'
                ,'issue_d'
                ,'emp'
                ,'title'
                ,'term'
                ,'purpose'
                ,'last_credit_pull_d'
                ,'initial_list_status'
                ,'grade'
                ,'loan_status'
                ,'bad_flag']
numCols = ['loan_amnt'
                ,'dti'
                ,'annual_inc'
                ,'delinq_2yrs'
                ,'inq_last_6mths'
                ,'mths_since_last_delinq'
                ,'mths_since_last_record'
                ,'open_acc'
                ,'pub_rec'
                ,'collections_12_mths_ex_med'
                ,'funded_amnt'
                ,'funded_amnt_inv'
                ,'int_rate'
                ,'installment'
                ,'revol_bal'
                ,'out_prncp'
                ,'out_prncp_inv'
                ,'total_pymnt'
                ,'total_pymnt_inv'
                ,'total_rec_prncp'
                ,'total_rec_int'
                ,'total_rec_late_fee'
                ,'recoveries'
                ,'collection_recovery_fee'
                ,'last_pymnt_amnt'
                ,'revol_util'
                ,'total_acc'
                ,'mths_since_last_major_derog'
                ,'acc_now_delinq'
                ,'tot_coll_amt'
                ,'tot_cur_bal'
                ,'total_rev_hi_lim']

data.head()

data.id.nunique()

data.member_id.nunique()

"""- Dataset ini terdiri dari 466.285 baris dan memiliki 74 kolom.
Diantaranya terdiri dari beberapa tipe data yaitu float64(46), int64(6), object(22).

- Kemudian untuk `kolom id` dan `member_id`semua value unik yang artinya untuk pemodelan nanti tidak dipakai dan kedua kolom ini akan di drop pada tahap selanjutnya.

- Selanjutnya, pembuangan fitur-fitur yang tidak berguna dilakukan. Contohnya seperti fitur yang merupakan id unik, berupa free text, nilainya kosong semua (NULL), dsb.
"""

cols_to_drop = [
    # id unik
    'id'
    , 'member_id'

    # free text
    , 'url'
    , 'desc'

    # beberapa kolom bernilai null semua dan kolom yang tidak berguna untuk pemodelan
    , 'zip_code'
    , 'annual_inc_joint'
    , 'dti_joint'
    , 'verification_status_joint'
    , 'open_acc_6m'
    , 'open_il_6m'
    , 'open_il_12m'
    , 'open_il_24m'
    , 'mths_since_rcnt_il'
    , 'total_bal_il'
    , 'il_util'
    , 'open_rv_12m'
    , 'open_rv_24m'
    , 'max_bal_bc'
    , 'all_util'
    , 'inq_fi'
    , 'total_cu_tl'
    , 'inq_last_12m'
    , 'sub_grade'
]

data = data.drop(cols_to_drop, axis=1)

data.head()

"""# `DEFINE TARGET VARIABLE / LABELING`

---

Dalam dataset ini terdapat beberapa data peminjam ada yang bisa membayar dengan tepat, ada yang telat, dan bahkan ada yang gagal bayar.

Maka dalam project ini saya ditugaskan melakukan modeling untuk credit risk prediction dan untuk target,

maka ditetapkan pada variabel `loan_status` karena dalam variabel tersebut terdapat informasi performa masing-masing peminjam terhadap peminjaman/kredit selama ini
"""

sns.countplot(x ='loan_status', data = data, palette = "Set1")
plt.show()

data.loan_status.value_counts(normalize=True)*100

"""Dapat dilihat bahwa variabel `loan_status` memiliki beberapa nilai:
- `Current` artinya pembayaran lancar
- `Charged Off` artinya pembayaran macet sehingga dihapusbukukan
- `Late` artinya pembayaran telat dilakukan
- `In Grace Period` artinya dalam masa tenggang
- `Fully Paid` artinya pembayaran lunas
- `Default` artinya pembayaran macet

Dari definisi-definisi tersebut, masing-masing peminjam bisa dikategorikan sebagai peminjam yang baik dan peminjam yang buruk

Tahap selanjutnya dapat dikatakan peminjam yang buruk adalah peminjam yang telat bayar samopai gagal bayar
"""

bad_status = [
    'Charged Off'
    , 'Default'
    , 'Does not meet the credit policy. Status:Charged Off'
    , 'Late (31-120 days)'
]

data['bad_flag'] = np.where(data['loan_status'].isin(bad_status), 1, 0)

data['bad_flag'].value_counts(normalize=True)*100

"""Setelah dilakukan pemisahan antara peminjam yang baik dan peminjam yang buruk maka terlihat bahwa terjadinya imbalanced data karena data peminjam yang baik sebesar 89 % sedangkan peminjam yang buruk hanya 10 %"""

data.drop('loan_status', axis=1, inplace=True)

"""# `DATA CLEANSING, PREPROCESSING, FEATURE ENGINEERING`

---

Pada step ini, dilakukan pembersihan/modifikasi beberapa fitur ke dalam format yang dapat digunakan untuk modeling.

### emp_length

`emp_length` merupakan data setiap peminjam terhadap lamanya mereka bekerja.

Pada tahap ini adalah memodifikasi `emp_length`. Contoh: 4 years menjadi 4
"""

data['emp_length'].unique()

data['emp_length_int'] = data['emp_length'].str.replace('\+ years', '')
data['emp_length_int'] = data['emp_length_int'].str.replace('< 1 year', str(0))
data['emp_length_int'] = data['emp_length_int'].str.replace(' years', '')
data['emp_length_int'] = data['emp_length_int'].str.replace(' year', '')

data['emp_length_int'] = data['emp_length_int'].astype(float)

data['emp_length_int'].unique()

data.drop('emp_length', axis=1, inplace=True)

"""### term

`term` disini menunjukan tenor pinjaman

Kolom `term` juga akan disimplifikasi dar 36 months menjadi hanya angka 36
"""

data['term'].unique()

data['term_int'] = data['term'].str.replace(' months', '')
data['term_int'] = data['term_int'].astype(float)

data.drop('term', axis=1, inplace=True)

"""### earliest_cr_line

Kolom `earliest_cr_line` merupakan data tanggal dibukanya akun kredit.

Untuk mempermudah tahap selanjutnya maka kolom `earliest_cr_line` akan dimodifikasi dari format bulan-tahun menjadi perhitungan berapa lama waktu berlalu sejak waktu tersebut.

Umumnya digunakan reference date = hari ini. Namun, karena dataset ini merupakan dataset tahun 2007-2014, maka akan lebih relevan jika menggunakan reference date di sekitar tahun 2017. Dalam contoh ini, digunakan tanggal 2017-12-01 sebagai reference date.
"""

data['earliest_cr_line'].head(3)

data['earliest_cr_line_date'] = pd.to_datetime(data['earliest_cr_line'], format='%b-%y')
data['earliest_cr_line_date'].head(3)

data['mths_since_earliest_cr_line'] = round(pd.to_numeric((pd.to_datetime('2017-12-01') - data['earliest_cr_line_date']) / np.timedelta64(1, 'M')))
data['mths_since_earliest_cr_line'].head(3)

data['mths_since_earliest_cr_line'].describe()

data[data['mths_since_earliest_cr_line']<0][['earliest_cr_line', 'earliest_cr_line_date', 'mths_since_earliest_cr_line']].head(3)

"""Terlihat ada nilai yang aneh, yaitu negatif.

Nilai negatif muncul karena fungsi Python salah menginterpretasikan tahun 62 menjadi tahun 2062, padahal seharusnya merupakan tahun 1962.

Untuk mengatasi hal ini, sederhananya nilai yang negatif diubah menjadi nilai maximum. Karena di sini nilai-nilai yang negatif artinya adalah data yang sudah tua (tahun 1900an), maka masih masuk akal jika saya mengganti nilai-nilai tersebut menjadi nilai terbesar.
"""

data.loc[data['mths_since_earliest_cr_line']<0, 'mths_since_earliest_cr_line'] = data['mths_since_earliest_cr_line'].max()

data.drop(['earliest_cr_line', 'earliest_cr_line_date'], axis=1, inplace=True)

"""### issue_d

`issue_d` kolom yang berisi informasi bulan didanainya pinjaman.

Konsep preprocessing yang dilakukan sama dengan yang dilakukan terhadap variabel `earliest_cr_line`
"""

data['issue_d_date'] = pd.to_datetime(data['issue_d'], format='%b-%y')
data['mths_since_issue_d'] = round(pd.to_numeric((pd.to_datetime('2017-12-01') - data['issue_d_date']) / np.timedelta64(1, 'M')))

data['mths_since_issue_d'].describe()

data.drop(['issue_d', 'issue_d_date'], axis=1, inplace=True)

"""### last_pymnt_d

`last_pymnt_d` merupakan informasi pembayaran terakhir yang diterima

Konsep preprocessing yang dilakukan masih sama dengan yang dilakukan terhadap variabel `earliest_cr_line`
"""

data['last_pymnt_d_date'] = pd.to_datetime(data['last_pymnt_d'], format='%b-%y')
data['mths_since_last_pymnt_d'] = round(pd.to_numeric((pd.to_datetime('2017-12-01') - data['last_pymnt_d_date']) / np.timedelta64(1, 'M')))

data['mths_since_last_pymnt_d'].describe()

data.drop(['last_pymnt_d', 'last_pymnt_d_date'], axis=1, inplace=True)

"""### next_pymnt_d

`next_pymnt_d` adalah kolom informasi tentang pembayaran berikutnya

Konsep preprocessing yang dilakukan sama dengan yang dilakukan terhadap variabel `earliest_cr_line`
"""

data['next_pymnt_d_date'] = pd.to_datetime(data['next_pymnt_d'], format='%b-%y')
data['mths_since_next_pymnt_d'] = round(pd.to_numeric((pd.to_datetime('2017-12-01') - data['next_pymnt_d_date']) / np.timedelta64(1, 'M')))

data['mths_since_next_pymnt_d'].describe()

data.drop(['next_pymnt_d', 'next_pymnt_d_date'], axis=1, inplace=True)

"""### last_credit_pull_d

`last_credit_pull_d` merupakan kolom berisi pengecekan terakhir kredit peminjam

Konsep preprocessing yang dilakukan sama dengan yang dilakukan terhadap variabel `earliest_cr_line`
"""

data['last_credit_pull_d_date'] = pd.to_datetime(data['last_credit_pull_d'], format='%b-%y')
data['mths_since_last_credit_pull_d'] = round(pd.to_numeric((pd.to_datetime('2017-12-01') - data['last_credit_pull_d_date']) / np.timedelta64(1, 'M')))

data['mths_since_last_credit_pull_d'].describe()

data.drop(['last_credit_pull_d', 'last_credit_pull_d_date'], axis=1, inplace=True)

data.head()

"""# `EXPLORATORY DATA ANALYSIS`

---

### Correlation Check

### Uni-variate Analysis
Individual Boxplot and Violinplot
"""

plt.figure(figsize=(25, 15))
n = 5
for i in range(0, len(numCols)):
    plt.subplot(n, math.ceil(len(numCols)/n), i+1)
    sns.boxplot(y=data[numCols[i]], color='#00af5f', orient='v')
    plt.tight_layout()

plt.figure(figsize=(25, 15))
n = 5
for i in range(0, len(numCols)):
    plt.subplot(n, math.ceil(len(numCols)/n), i+1)
    sns.violinplot(y=data[numCols[i]], color='#00af5f',orient='v')
    plt.tight_layout()

plt.figure(figsize=(25, 15))
n = 5
for i in range(0, len(numCols)):
    plt.subplot(n, math.ceil(len(numCols)/n), i+1)
    sns.histplot(data[numCols[i]], color='#00af5f', kde=True)
    plt.tight_layout()

sns.countplot(y ='verification_status', data = data, palette = "Set1")
plt.show()

sns.countplot(y ='grade', data = data, palette = "Set1")
plt.show()

sns.countplot(y ='purpose', data = data, palette = "Set1")
plt.show()

sns.countplot(x ='bad_flag', data = data, palette = "Set1")
plt.show()

sns.countplot(x ='emp_length_int', data = data, palette = "Set1")
plt.show()

plt.figure(figsize=(30,20))
sns.heatmap(data.corr(), cmap='Greens', annot=True, fmt='.2f')

"""Di sini, jika ada pasangan fitur-fitur yang memiliki korelasi tinggi maka akan diambil salah satu saja. Nilai korelasi yang dijadikan patokan sebagai korelasi tinggi tidak pasti, umumnya digunakan angka 0.7."""

corr_matrix = data.corr().abs()
upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))
to_drop_hicorr = [column for column in upper.columns if any(upper[column] > 0.7)]

to_drop_hicorr

data.drop(to_drop_hicorr, axis=1, inplace=True)

"""### Check Categorical Features"""

data.select_dtypes(include='object').nunique()

"""Pada tahap ini dilakukan pembuangan fitur yang memiliki nilai unik yang sangat tinggi (high cardinality) dan fitur yang hanya memiliki satu nilai unik saja."""

data.drop(['emp_title', 'title', 'application_type'], axis=1, inplace=True)

data.select_dtypes(exclude='object').nunique()

"""Ternyata, pada tipe data selain `object` juga terdapat fitur yang hanya memiliki satu nilai unik saja, maka akan ikut dibuang juga."""

data.drop(['policy_code'], axis=1, inplace=True)

for col in data.select_dtypes(include='object').columns.tolist():
    print(data[col].value_counts(normalize=True)*100)
    print('\n')

"""Fitur yang sangat didominasi oleh salah satu nilai saja akan dibuang pada tahap ini."""

data.drop('pymnt_plan', axis=1, inplace=True)

"""# MISSING VALUES

### Missing Value Checking
"""

print('Missing values status:', data.isnull().values.any())
nvc = pd.DataFrame(data.isnull().sum().sort_values(), columns=['Total Null Values'])
nvc['Percentage'] = (nvc['Total Null Values']/data.shape[0])*100
nvc["Data Type"] = [data[col].dtype for col in data.columns]
nvc.sort_values(by=["Total Null Values", "Percentage"], ascending=False, inplace=True)
nvc["NULL Values"] = data[nvc.index].isnull().sum()
nvc

"""Di sini, kolom-kolom dengan missing values di atas 75% dibuang dan kemudian pada missing value di beberapa kolom bisa diisi dengan '0' saja"""

data.drop('mths_since_last_record', axis=1, inplace=True)

"""### Missing Values Filling"""

data['annual_inc'].fillna(data['annual_inc'].mean(), inplace=True)
data['mths_since_earliest_cr_line'].fillna(0, inplace=True)
data['acc_now_delinq'].fillna(0, inplace=True)
data['total_acc'].fillna(0, inplace=True)
data['pub_rec'].fillna(0, inplace=True)
data['open_acc'].fillna(0, inplace=True)
data['inq_last_6mths'].fillna(0, inplace=True)
data['delinq_2yrs'].fillna(0, inplace=True)
data['collections_12_mths_ex_med'].fillna(0, inplace=True)
data['revol_util'].fillna(0, inplace=True)
data['emp_length_int'].fillna(0, inplace=True)
data['tot_cur_bal'].fillna(0, inplace=True)
data['tot_coll_amt'].fillna(0, inplace=True)
data['mths_since_last_delinq'].fillna(-1, inplace=True)

data.isna().sum()

"""# `FEATURE SCALING AND TRANSFORMATION`
---
"""

data.sample()

"""### One Hot Encoding

Semua kolom kategorikal dilakukan One Hot Encoding.
"""

categorical_cols = [col for col in data.select_dtypes(include='object').columns.tolist()]

onehot = pd.get_dummies(data[categorical_cols], drop_first=True)

onehot.head()

"""### Standardization

Semua kolom numerikal dilakukan proses standarisasi dengan StandardScaler.
"""

numerical_cols = [col for col in data.columns.tolist() if col not in categorical_cols + ['bad_flag']]

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
std = pd.DataFrame(ss.fit_transform(data[numerical_cols]), columns=numerical_cols)

std.head()

"""### Transformed Dataframe

Menggabungkan kembali kolom-kolom hasil transformasi
"""

data_model = pd.concat([onehot, std, data[['bad_flag']]], axis=1)

"""# MODELING

### Train-Test Split
"""

from sklearn.model_selection import train_test_split

X = data_model.drop('bad_flag', axis=1)
y = data_model['bad_flag']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_train.shape, X_test.shape

"""### Training"""

from sklearn.linear_model import LogisticRegression #logistic regression
from sklearn.naive_bayes import GaussianNB #gaussian naive bayes
from sklearn import tree
from sklearn.tree import DecisionTreeClassifier #decision tree
from sklearn.ensemble import RandomForestClassifier #random forest
from sklearn.neighbors import KNeighborsClassifier #k-nearest neighbor
from sklearn.svm import SVC # Support Vector Machine/Classifier
from sklearn.neural_network import MLPClassifier #neural network
from sklearn.ensemble import GradientBoostingClassifier #gradient boosting
from xgboost import XGBClassifier #xgboost
from sklearn.ensemble import AdaBoostClassifier #Adaboost

from sklearn import metrics
from sklearn.model_selection import cross_val_score, cross_validate
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score
from sklearn.metrics import roc_auc_score, roc_curve #roc score
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.inspection import permutation_importance
from sklearn.model_selection import RandomizedSearchCV, GridSearchCV
from scipy.stats import uniform

import re
import warnings
warnings.filterwarnings('ignore')

"""##  Function for Model Evaluation"""

train_classifier_list = []
train_modelname_list = []
train_accuracy_list = []
train_precision_list = []
train_recall_list = []
train_f1_score_list= []
train_roc_auc_score_list = []
train_cross_val_f1_list = []
train_cross_val_rocauc_list = []

test_classifier_list = []
test_modelname_list = []
test_accuracy_list = []
test_precision_list = []
test_recall_list = []
test_f1_score_list= []
test_roc_auc_score_list = []
test_cross_val_f1_list = []
test_cross_val_rocauc_list = []

from sklearn.utils import shuffle
from sklearn.model_selection import KFold
X_s, y_s = shuffle(X, y, random_state=42)
kf = KFold(10, shuffle=True, random_state=0)

"""## Function Evaluation for Recap Classification"""

def eval_classification(model, model_name, save=True):
    # predict train
    y_train_pred = model.predict(X_train)
    y_train_pred_prob = model.predict_proba(X_train)

    # predict test
    y_test_pred = model.predict(X_test)
    y_test_pred_prob = model.predict_proba(X_test)

    # cross validation
    cv_score_f1 = cross_validate(model, X_s, y_s, cv=kf, scoring='f1', return_train_score=True)
    cv_score_rocauc = cross_validate(model, X_s, y_s, cv=kf, scoring='roc_auc', return_train_score=True)


    accuracy_train = round(accuracy_score(y_train, y_train_pred), 3)
    precision_train = round(precision_score(y_train, y_train_pred), 3)
    recall_train = round(recall_score(y_train, y_train_pred), 3)
    f1_s_train = round(f1_score(y_train, y_train_pred), 3)
    csf_score_train = round(cv_score_f1['train_score'].mean(), 3)
    rocauc_score_train = round(roc_auc_score(y_train, y_train_pred_prob[:, 1]), 3)
    csr_score_train = round(cv_score_rocauc['train_score'].mean(), 3)

    accuracy_test = round(accuracy_score(y_test, y_test_pred), 3)
    precision_test = round(precision_score(y_test, y_test_pred), 3)
    recall_test = round(recall_score(y_test, y_test_pred), 3)
    f1_s_test = round(f1_score(y_test, y_test_pred), 3)
    csf_score_test = round(cv_score_f1['test_score'].mean(), 3)
    rocauc_score_test = round(roc_auc_score(y_test, y_test_pred_prob[:, 1]), 3)
    csr_score_test = round(cv_score_rocauc['test_score'].mean(), 3)

    if save :

        # save report detail train
        train_classifier_list.append(model)
        train_modelname_list.append(model_name)
        train_accuracy_list.append(accuracy_train)
        train_precision_list.append(precision_train)
        train_recall_list.append(recall_train)
        train_f1_score_list.append(f1_s_train)
        train_cross_val_f1_list.append(csf_score_train)
        train_roc_auc_score_list.append(rocauc_score_train)
        train_cross_val_rocauc_list.append(csr_score_train)

        # save report detail test
        test_classifier_list.append(model)
        test_modelname_list.append(model_name)
        test_accuracy_list.append(accuracy_test)
        test_precision_list.append(precision_test)
        test_recall_list.append(recall_test)
        test_f1_score_list.append(f1_s_test)
        test_cross_val_f1_list.append(csf_score_test)
        test_roc_auc_score_list.append(rocauc_score_test)
        test_cross_val_rocauc_list.append(csr_score_test)


    metrics_summary = pd.DataFrame({
        'Evaluation Metrics' : ["Accuracy", "Precision", "Recall", "F1 Score", "F1 Score (crossval)", "ROC AUC", "ROC AUC (crossval)"],
        'Train' : [accuracy_train, precision_train, recall_train, f1_s_train, csf_score_train, rocauc_score_train, csr_score_train],
        'Test' : [accuracy_test, precision_test, recall_test, f1_s_test, csf_score_test, rocauc_score_test, csr_score_test]})

    metrics_summary["Diff Range"] = metrics_summary['Train'] - metrics_summary['Test']
    return metrics_summary.reset_index(drop = True).style.background_gradient(cmap='Purples')

# define function to see the best tuning hyperparameter
def show_best_hyperparameter(model):
    print(model.best_estimator_.get_params())

"""## Function Evaluation for Training"""

def model_eval_train(classifier, model_name, X_train, y_train):
    # predict data train
    y_train_pred = classifier.predict(X_train)
    y_train_pred_prob = classifier.predict_proba(X_train)

    # print classification report
    print('Classification Report Training Model ('+model_name+'):\n')
    accuracy = round(accuracy_score(y_train, y_train_pred), 3)
    precision = round(precision_score(y_train, y_train_pred), 3)
    recall = round(recall_score(y_train, y_train_pred), 3)
    f1_s = round(f1_score(y_train, y_train_pred), 3)
    rocauc_score = round(roc_auc_score(y_train, y_train_pred_prob[:, 1]), 3)

    # c_val_score = round(cross_val_score(classifier, X_s, y_s, cv=kf, scoring='roc_auc').mean()  , 3)
    cv_score_f1 = cross_validate(classifier, X_s, y_s, cv=kf, scoring='f1', return_train_score=True)
    csf_score = round(cv_score_f1['train_score'].mean(), 3)

    cv_score_rocauc = cross_validate(classifier, X_s, y_s, cv=kf, scoring='roc_auc', return_train_score=True)
    csr_score = round(cv_score_rocauc['train_score'].mean(), 3)

    print(f'Accuracy = {accuracy}')
    print(f'Precision = {precision}')
    print(f'Recall = {recall}')
    print(f'F1 Score = {f1_s}')
    print(f'Cross Val F1 (k=5) = {csf_score}')
    print(f'ROC AUC = {rocauc_score}')
    print(f'Cross Val ROC AUC (k=5) = {csr_score}\n')

    print(classification_report(y_train, y_train_pred))

    # form confusion matrix as a dataFrame
    conf_matrix = pd.DataFrame((confusion_matrix(y_train, y_train_pred)), ('good', 'bad'), ('good', 'bad'))
    tn, fp, fn, tp = confusion_matrix(y_train, y_train_pred).ravel()

    print("==== Actual Data (Train) =====")
    print("Total =", len(y_train))
    print("good =", len(y_train[y_train == 0]))
    print("bad =", len(y_train[y_train == 1]))
    print("==== Predicted Data (Train) =====")
    print("TP = {}, FP = {}, TN = {}, FN = {}".format(tp, fp, tn, fn))
    print("Predictly Correct =", tn+tp)
    print("Predictly Wrong =", fn+fp, "\n")

    # plot confusion matrix
    plt.figure(figsize=[8,5])

    c_matrix = confusion_matrix(y_train, y_train_pred)
    names = ['True Negative', 'False Positive', 'False Negative', 'True Positive']
    counts = ['{0:0.0f}'.format(value) for value in c_matrix.flatten()]
    percentages = ['{0:.2%}'.format(value) for value in c_matrix.flatten() / np.sum(c_matrix)]
    labels = [f'{v1}\n{v2}\n{v3}' for v1, v2, v3 in zip(names, counts, percentages)]
    labels = np.asarray(labels).reshape(2, 2)

    heatmap = sns.heatmap(conf_matrix, annot = labels, annot_kws={'size': 13}, fmt='', cmap='Greens')
    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=13)
    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right', fontsize=13)

    plt.title('Confusion Matrix for Training Model ('+model_name+')\n', fontsize=13, color='black')
    plt.ylabel('Actual Label', fontsize=13)
    plt.xlabel('\nPredicted Label', fontsize=13)
    plt.show()
    print("\n")

    # ROC AUC Curve
    plt.figure(figsize=[8,5])
    fpr, tpr, threshold = roc_curve(y_train, y_train_pred_prob[:, 1])
    plt.plot(fpr, tpr, label = model_name+' (Area (Score) = %0.2f)'%rocauc_score)
    plt.plot([0,1],[0,1],'r--')
    plt.xlim([0.0,1.0])
    plt.ylim([0.0,1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Is Data Good or Bad')
    plt.legend(loc="lower right")
    plt.show()

"""## Function Evaluation for Test"""

def model_eval_test(classifier, model_name, X_test, y_test):

     # predict data test
    y_test_pred = classifier.predict(X_test)
    y_test_pred_prob = classifier.predict_proba(X_test)


    # print classification report
    print('Classification Report Testing Model ('+model_name+'):\n')
    accuracy = round(accuracy_score(y_test, y_test_pred), 3)
    precision = round(precision_score(y_test, y_test_pred), 3)
    recall = round(recall_score(y_test, y_test_pred), 3)
    f1_s = round(f1_score(y_test, y_test_pred), 3)
    rocauc_score = round(roc_auc_score(y_test, y_test_pred_prob[:, 1]), 3)

    # c_val_score = round(cross_val_score(classifier, X_s, y_s , cv=kf , scoring='roc_auc').mean()  , 3)
    cv_score_f1 = cross_validate(classifier, X_s, y_s, cv=kf, scoring='f1', return_train_score=True)
    csf_score = round(cv_score_f1['test_score'].mean(), 3)

    cv_score_rocauc = cross_validate(classifier, X_s, y_s, cv=kf, scoring='roc_auc', return_train_score=True)
    csr_score = round(cv_score_rocauc['test_score'].mean(), 3)

    print(f'Accuracy = {accuracy}')
    print(f'Precision = {precision}')
    print(f'Recall = {recall}')
    print(f'F1 Score = {f1_s}')
    print(f'Cross Val F1 (k=5) = {csf_score}')
    print(f'ROC AUC = {rocauc_score}')
    print(f'Cross Val ROC AUC (k=5) = {csr_score}\n')

    print(classification_report(y_test, y_test_pred))

    # form confusion matrix as a dataFrame
    conf_matrix = pd.DataFrame((confusion_matrix(y_test, y_test_pred)), ('good', 'bad'), ('good', 'bad'))
    tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()

    print("==== Actual Data (Test) =====")
    print("Total =", len(y_test))
    print("good =", len(y_test[y_test == 0]))
    print("bad =", len(y_test[y_test == 1]))
    print("==== Predicted Data (Test) =====")
    print("TP = {}, FP = {}, TN = {}, FN = {}".format(tp, fp, tn, fn))
    print("Predictly Correct =", tn+tp)
    print("Predictly Wrong =", fn+fp, "\n")

    # plot confusion matrix
    plt.figure(figsize=[8,5])

    c_matrix = confusion_matrix(y_test, y_test_pred)
    names = ['True Negative', 'False Positive', 'False Negative', 'True Positive']
    counts = ['{0:0.0f}'.format(value) for value in c_matrix.flatten()]
    percentages = ['{0:.2%}'.format(value) for value in c_matrix.flatten() / np.sum(c_matrix)]
    labels = [f'{v1}\n{v2}\n{v3}' for v1, v2, v3 in zip(names, counts, percentages)]
    labels = np.asarray(labels).reshape(2, 2)

    heatmap = sns.heatmap(conf_matrix, annot = labels, annot_kws={'size': 13}, fmt='', cmap='Oranges')
    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=13)
    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right', fontsize=13)

    plt.title('Confusion Matrix for Testing Model ('+model_name+')\n', fontsize=13, color='black')
    plt.ylabel('Actual Label', fontsize=13)
    plt.xlabel('\nPredicted Label', fontsize=13)
    plt.show()
    print("\n")

    # ROC AUC Curve
    plt.figure(figsize=[8,5])
    fpr, tpr, threshold = roc_curve(y_test, y_test_pred_prob[:, 1])
    plt.plot(fpr, tpr, label = model_name+' (Area (Score) = %0.2f)'%rocauc_score)
    plt.plot([0,1],[0,1],'r--')
    plt.xlim([0.0,1.0])
    plt.ylim([0.0,1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Is Data Good or Bad')
    plt.legend(loc="lower right")
    plt.show()

"""# `TRAINING`
---

## Decision Tree
"""

# train the model
dt_model = DecisionTreeClassifier(random_state=42).fit(X_train,y_train)
print(dt_model)
eval_classification(dt_model, "Decision Tree")

model_eval_train(dt_model, "Decision Tree", X_train, y_train)

model_eval_test(dt_model, "Decision Tree", X_test, y_test)

acc_dt_train=round(dt_model.score(X_train,y_train)*100,2)
acc_dt_test=round(dt_model.score(X_test,y_test)*100,2)
print("Training Accuracy: {} %".format(acc_dt_train))
print("Testing Accuracy: {} %".format(acc_dt_test))

"""## Naive Bayes"""

# train the model
gnb_model = GaussianNB().fit(X_train, y_train)
print(gnb_model)
eval_classification(gnb_model, "Naive Bayes")

model_eval_train(gnb_model, "Naive Bayes", X_train, y_train)

model_eval_test(gnb_model, "Naive Bayes", X_test, y_test)

acc_gnb_train=round(gnb_model.score(X_train,y_train)*100,2)
acc_gnb_test=round(gnb_model.score(X_test,y_test)*100,2)
print("Training Accuracy: {} %".format(acc_gnb_train))
print("Test Accuracy: {} %".format(acc_gnb_test))

"""## AdaBoostClassifier"""

# train the model
adab_model = AdaBoostClassifier(random_state=42).fit(X_train, y_train)
eval_classification(adab_model, "Adaboost Classifier")

model_eval_train(adab_model, "Adaboost Classifier", X_train, y_train)

model_eval_test(adab_model, "Adaboost Classifier", X_test, y_test)

acc_adab_train=round(adab_model.score(X_train,y_train)*100,2)
acc_adab_test=round(adab_model.score(X_test,y_test)*100,2)
print("Training Accuracy: {} %".format(acc_adab_train))
print("Test Accuracy: {} %".format(acc_adab_test))

# train the model
log_model = LogisticRegression(solver='lbfgs', max_iter=len(X_train), random_state=42).fit(X_train, y_train)
print(log_model)
eval_classification(log_model, "Logistic Regression")

model_eval_train(log_model, "Logistic Regression", X_train, y_train)

model_eval_test(log_model, "Logistic Regression", X_test, y_test)

acc_log_train=round(log_model.score(X_train,y_train)*100,2)
acc_log_test=round(log_model.score(X_test,y_test)*100,2)
print("Training Accuracy: {} %".format(acc_log_train))
print("Test Accuracy: {} %".format(acc_log_test))

results_eval = pd.DataFrame({
    "Models" : train_modelname_list,
    "Precision (Train)": train_precision_list,
    "Precision (Test)": test_precision_list,
    "Recall (Train)": train_recall_list,
    "Recall (Test)": test_recall_list,
    "F1 Score (Train)" : train_f1_score_list,
    "F1 Score (Test)" : test_f1_score_list
})

results_eval.drop_duplicates(inplace = True)

results_eval.sort_values(by=["F1 Score (Test)", "Precision (Test)", "Recall (Test)"], ascending=[False, False, False]).reset_index(drop = True).style.background_gradient(cmap="Purples")

"""Pada contoh ini digunakan algoritma Random Forest untuk pemodelan."""

from sklearn.ensemble import RandomForestClassifier

rfc = RandomForestClassifier(max_depth=4)
rfc.fit(X_train, y_train)

"""Feature Importance dapat ditampilkan."""

arr_feature_importances = rfc.feature_importances_
arr_feature_names = X_train.columns.values

df_feature_importance = pd.DataFrame(index=range(len(arr_feature_importances)), columns=['feature', 'importance'])
df_feature_importance['feature'] = arr_feature_names
df_feature_importance['importance'] = arr_feature_importances
df_all_features = df_feature_importance.sort_values(by='importance', ascending=False)
df_all_features

"""### Validation

Untuk mengukur performa model, dua metrik yang umum dipakai dalam dunia credit risk adalah AUC dan KS.
"""

y_pred_proba = rfc.predict_proba(X_test)[:][:,1]

df_actual_predicted = pd.concat([pd.DataFrame(np.array(y_test), columns=['y_actual']), pd.DataFrame(y_pred_proba, columns=['y_pred_proba'])], axis=1)
df_actual_predicted.index = y_test.index

"""#### AUC"""

from sklearn.metrics import roc_curve, roc_auc_score

fpr, tpr, tr = roc_curve(df_actual_predicted['y_actual'], df_actual_predicted['y_pred_proba'])
auc = roc_auc_score(df_actual_predicted['y_actual'], df_actual_predicted['y_pred_proba'])

plt.plot(fpr, tpr, label='AUC = %0.4f' %auc)
plt.plot(fpr, fpr, linestyle = '--', color='k')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()

"""#### KS"""

df_actual_predicted = df_actual_predicted.sort_values('y_pred_proba')
df_actual_predicted = df_actual_predicted.reset_index()

df_actual_predicted['Cumulative N Population'] = df_actual_predicted.index + 1
df_actual_predicted['Cumulative N Bad'] = df_actual_predicted['y_actual'].cumsum()
df_actual_predicted['Cumulative N Good'] = df_actual_predicted['Cumulative N Population'] - df_actual_predicted['Cumulative N Bad']
df_actual_predicted['Cumulative Perc Population'] = df_actual_predicted['Cumulative N Population'] / df_actual_predicted.shape[0]
df_actual_predicted['Cumulative Perc Bad'] = df_actual_predicted['Cumulative N Bad'] / df_actual_predicted['y_actual'].sum()
df_actual_predicted['Cumulative Perc Good'] = df_actual_predicted['Cumulative N Good'] / (df_actual_predicted.shape[0] - df_actual_predicted['y_actual'].sum())

df_actual_predicted.head()

KS = max(df_actual_predicted['Cumulative Perc Good'] - df_actual_predicted['Cumulative Perc Bad'])

plt.plot(df_actual_predicted['y_pred_proba'], df_actual_predicted['Cumulative Perc Bad'], color='r')
plt.plot(df_actual_predicted['y_pred_proba'], df_actual_predicted['Cumulative Perc Good'], color='b')
plt.xlabel('Estimated Probability for Being Bad')
plt.ylabel('Cumulative %')
plt.title('Kolmogorov-Smirnov:  %0.4f' %KS)

"""Model yang dibangun menghasilkan performa `AUC = 0.857` dan `KS = 0.56`. Pada dunia credit risk modeling, umumnya AUC di atas 0.7 dan KS di atas 0.3 sudah termasuk performa yang baik."""